---
title: 'RLHF Derivation'
date: 2025-07-31
permalink: /posts/2025/07/blog-post-1/
tags:
  - RL
---

Personal derivation of some important RLHF theorems.

Policy Gradient
======

We aim to maximize the expected return

$$
J\left(\pi_\theta\right)=\underset{\tau \sim \pi_\theta}{\mathrm{E}}[R(\tau)].
$$

I prefer to use the expression in integral form

$$
J\left(\pi_ \theta\right)=\int_{\tau}P_\theta \left( \tau \right) R\left( \tau \right),
$$

$$
\begin{align*}
\nabla_\theta J\left(\pi_\theta \right)
&=\nabla_\theta \int_{\tau}P_\theta\left(\tau \right)R\left(\tau \right) \\
&=\int_{\tau}\nabla_\theta P_\theta\left(\tau \right)R\left(\tau \right) \\
&=\int_{\tau}P_\theta\left(\tau \right)\nabla_\theta \log{P_\theta\left(\tau \right)}  R\left(\tau \right).
\end{align*}
$$

The dynamic sampling in DAPO actually alters the sampling distribution.

Reward-to-Go
------
$$
\begin{align*}
\nabla_\theta J\left(\pi_\theta \right)
&=\int_{\tau}P_\theta\left(\tau \right)\nabla_\theta \log{\prod_{t=0}^{T} \pi_\theta\left(a_t\mid s_t\right) }  R\left(\tau \right) \\
&=\int_{\tau}P_\theta\left(\tau \right)\nabla_\theta \sum_{t=0}^{T}  \log{\pi_\theta\left(a_t\mid s_t\right) }  R\left(\tau \right) \\
&=\int_{\tau}P_\theta\left(\tau \right)\nabla_\theta \sum_{t=0}^{T}  \log{\pi_\theta\left(a_t\mid s_t\right) } \sum_{t^\prime=0}^{T} R\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime + 1}\right) \\
&=\int_{\tau}P_\theta\left(\tau \right)\sum_{t=0}^{T}\nabla_\theta\log{\pi_\theta\left(a_t\mid s_t\right) } \sum_{t^\prime=0}^{T} R\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime + 1}\right) \\
&=\boxed{ \int_{\tau}P_\theta\left(\tau \right)\sum_{t=0}^{T}\nabla_\theta \log{\pi_\theta\left(a_t\mid s_t\right) } \sum_{t^\prime=0}^{t-1} R\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime + 1}\right)} + \int_{\tau}P_\theta\left(\tau \right)\sum_{t=0}^{T}\nabla_\theta \log{\pi_\theta\left(a_t\mid s_t\right) } \sum_{t^\prime=t}^{T} R\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime + 1}\right)
\end{align*}
$$

We will prove that the boxed term equals to $$0$$.

Expected Grad-Log-Prob (EGLP) lemma:

$$
\int_x P_\theta(x)=1.
$$

$$
\nabla_\theta \int_x P_\theta(x)=\nabla_\theta 1=0.
$$

$$
\begin{aligned}
0 & =\nabla_\theta \int_x P_\theta(x) \\
& =\int_x \nabla_\theta P_\theta(x) \\
& =\int_x P_\theta(x) \nabla_\theta \log P_\theta(x).
\end{aligned}
$$

$$
\int_{\tau}P_\theta\left(\tau \right)\sum_{t=0}^{T}\nabla_\theta \log{\pi_\theta\left(a_t\mid s_t\right) } \sum_{t^\prime=0}^{t-1} R\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime + 1}\right) = \int_{\tau}P_\theta\left(\tau \right)\sum_{t=0}^{T} \sum_{t^\prime=0}^{t-1} \nabla_\theta \log{\pi_\theta\left(a_t\mid s_t\right) } R\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime + 1}\right).
$$

For a specific $$t$$ and $$t^\prime$$, we get $$\int_{\tau}P_\theta\left(\tau \right)\nabla_\theta \log{\pi_\theta\left(a_t\mid s_t\right) } R\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime + 1}\right)$$.
For trajactories that has the same $$a_t, s_t, s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1}$$, they have the same $$\nabla_\theta \log{\pi_\theta\left(a_t\mid s_t\right) } R\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime + 1}\right)$$.
So, we can add their probbilities directly, which is $$P_\theta\left(a_t, s_t, s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1} \right)$$.
In this way, we transform above term to:

$$
\int_{a_t, s_t, s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1}}P_\theta\left(a_t, s_t, s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1} \right)\nabla_\theta \log{\pi_\theta\left(a_t\mid s_t\right) } R\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime + 1}\right).
$$

$$\int_{a_t, s_t, s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1}}$$ indicates sampling $$a_t, s_t, s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1}$$ from $$\pi_\theta$$.
Note that $$a_t, s_t, s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1}$$ are still variables; $$t$$ and $$t^\prime$$ are constants.

Using the marginal distribution, we get:

$$
\begin{aligned}
& \int_{a_t, s_t, s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1}}P_\theta\left(a_t, s_t, s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1} \right)\nabla_\theta \log{\pi_\theta\left(a_t\mid s_t\right) } R\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime + 1}\right) \\
& = \int_{a_t, s_t} \int_{s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1}} P_\theta\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1} \right) P_\theta\left(a_t, s_t \mid s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1} \right) \nabla_\theta \log{\pi_\theta\left(a_t\mid s_t\right) } R\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime + 1}\right) \\
& = \int_{s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1}} P_\theta\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1} \right) \int_{a_t, s_t}   P_\theta\left(a_t, s_t \mid s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1} \right) \nabla_\theta \log{\pi_\theta\left(a_t\mid s_t\right) } R\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime + 1}\right) \\
& = \int_{s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1}} P_\theta\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1} \right) R\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime + 1}\right) \int_{a_t, s_t}   P_\theta\left(a_t, s_t \mid s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1} \right) \nabla_\theta \log{\pi_\theta\left(a_t\mid s_t\right) } \\
& = \int_{s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1}} P_\theta\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1} \right) R\left(s_{t^\prime}, a_{t^\prime}, s_{t^\prime + 1}\right) \int_{s_t} P_\theta\left(s_t \mid s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1} \right)\boxed{ \int_{a_t} \pi_\theta\left(a_t \mid s_t \right) \nabla_\theta \log{\pi_\theta\left(a_t\mid s_t\right) } }
\end{aligned}
$$

According to EGLP, the boxed part equals to $$0$$.

When $$t^\prime > t$$, we cannot do $$P_\theta\left(a_t, s_t \mid s_{t^\prime}, a_{t^\prime}, s_{s^\prime+1}\right)=\pi_\theta\left(a_t \mid s_t \right) P_\theta\left(s_t \mid s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1} \right)$$.
We can only do $$P_\theta\left(a_t, s_t \mid s_{t^\prime}, a_{t^\prime}, s_{s^\prime+1}\right)=P_\theta\left(a_t \mid s_t, s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1} \right) P_\theta\left(s_t \mid s_{t^\prime}, a_{t^\prime}, s_{t^\prime+1} \right)$$.

Baseline
------

When we add a baseline $$b\left(s_t\right)$$ to $$R$$

$$
\begin{aligned}
\Delta \nabla_\theta J\left(\pi_\theta \right)=\sum_{t=0}^{T} \int_\tau P_\theta \left(\tau\right) \nabla_\theta \log{\pi_\theta \left(a_t \mid s_t \right)} b\left(s_t\right).
\end{aligned}
$$

Similar to the method in Reward-to-Go,

$$
\begin{aligned}
\Delta \nabla_\theta J\left(\pi_\theta \right)
& =\sum_{t=0}^{T} \int_{a_t, s_t} P_\theta \left(a_t, s_t\right) \nabla_\theta \log{\pi_\theta \left(a_t \mid s_t \right)} b\left(s_t\right) \\
& = \sum_{t=0}^{T} \int_{s_t} P_\theta\left(s_t \right) \int_{a_t} P_\theta \left(a_t \mid s_t\right) \nabla_\theta \log{\pi_\theta \left(a_t \mid s_t \right)} b\left(s_t\right) \\
& = \sum_{t=0}^{T} \int_{s_t} P_\theta\left(s_t \right) b\left(s_t\right) \boxed{ \int_{a_t} P_\theta \left(a_t \mid s_t\right) \nabla_\theta \log{\pi_\theta \left(a_t \mid s_t \right)}}.
\end{aligned}
$$

According to EGLP, the boxed part equals to $$0$$.

<!-- <img src="/files/images/test.jpg" alt="测试图片" width="400"/>

![一张测试图片](/files/images/test.jpg) -->